from openai import OpenAI
import os
from vector_store import search_faiss

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

system_message = """
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡∏•‡∏≠‡∏á‡∏ñ‡∏°‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏°‡∏≠‡∏•‡∏•‡πå ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
"""

def answer_question(user_message):
    context = search_faiss(user_message)

    # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö context ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å keyword
    if not context:
        similar_context = search_faiss(user_message[:4])  # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏£‡∏´‡∏±‡∏™/‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
        if similar_context:
            return f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö: '{user_message}'\n‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:\n{similar_context[:1000]}"
        else:
            return f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: '{user_message}'"

    # ‚úÖ ‡∏ï‡∏±‡∏î context ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
    context = context[:2000]

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤:\n{context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:\n{user_message}"}
        ],
        temperature=0.5,   # üëà ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏´‡∏•‡∏∏‡∏î‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠
        max_tokens=300     # üëà ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
    )

    return response.choices[0].message.content.strip()


