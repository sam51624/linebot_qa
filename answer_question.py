from search_products import search_products
from vector_store import search_faiss
from openai import OpenAI
import os

chat_history = {}
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

system_message = """
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡∏•‡∏≠‡∏á‡∏ñ‡∏°‡∏ä‡πâ‡∏≠‡∏õ‡∏õ‡∏¥‡πâ‡∏á‡∏°‡∏≠‡∏•‡∏•‡πå ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
"""

def normalize_text(text):
    if not text:
        return ""
    return text.strip().replace(" ", "").replace("-", "").lower()

def answer_question(user_message, user_id=None):
    if not user_message:
        return "‚ùóÔ∏è‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ñ‡πà‡∏∞"

    cleaned_message = normalize_text(user_message)

    # ‚úÖ 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö keyword match ‡∏à‡∏≤‡∏Å Google Sheet
    try:
        result = search_products(cleaned_message)
        if "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤" not in result:
            return result
    except Exception as e:
        print("‚ùå Error in search_products:", str(e))

    # ‚úÖ 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Vector Search ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏≤‡∏Å Google Sheet
    try:
        context = search_faiss(cleaned_message)
        if context:
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤:\n{context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:\n{user_message}"}
            ]

            # ‚úÖ 3. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ memory
            if user_id:
                user_chat = chat_history.get(user_id, [])[-3:]
                for m in user_chat:
                    messages.insert(-1, m)
                chat_history.setdefault(user_id, []).append({"role": "user", "content": user_message})

            # ‚úÖ 4. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å GPT ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å context
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages,
                temperature=0.5,
                max_tokens=300
            )
            reply = response.choices[0].message.content.strip()

            if user_id:
                chat_history[user_id].append({"role": "assistant", "content": reply})

            return f"üîç ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏£‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡πÅ‡∏ï‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á:\n\n{reply}"
    except Exception as e:
        print("‚ùå Error in vector search + GPT:", str(e))

    return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏°‡∏≤‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üôè"

